# Qwen3-1.7B 医学领域全参数微调实验报告
## 一、实验概述
### （一）实验背景
Qwen3是阿里通义实验室开源的大语言模型，发布时登顶开源LLM榜单第一名，且Qwen系列模型已成为HuggingFace上最受欢迎的开源LLM，在研究学习与应用落地场景中均展现出优异潜力。为实现Qwen3在医学垂直领域的专业化应用，使其能够支持DeepSeek R1式带推理过程的对话回复，本次实验以Qwen3-1.7B为基座模型，开展全参数微调训练。


![img.png](img.png)
### （二）实验目标
1. 基于delicate_medical_r1_data医学对话数据集，通过全参数微调让Qwen3-1.7B模型掌握医学问题的推理逻辑与专业回复能力。
2. 实现模型输出包含“思考过程+最终答案”的组合回复，且思考过程与答案在展示形式上有明确区分。
3. 利用SwanLab工具监控训练过程，评估模型训练效果，验证全参数微调在医学领域对话任务中的可行性。

### （三）核心技术与工具
|类别|具体内容|
| ---- | ---- |
|基座模型|Qwen3-1.7B（Modelscope获取）|
|数据集|delicate_medical_r1_data（含2000+条医学对话数据）|
|核心框架|Python>=3.8、PyTorch、CUDA|
|关键库|modelscope==1.22.0、transformers>=4.50.0、datasets==3.2.0、accelerate、pandas、addict、swanlab==0.5.7|
|训练监控工具|SwanLab（开源AI模型训练跟踪与可视化工具）|
|硬件要求|英伟达/昇腾显卡（显存≥32GB）|

## 二、实验原理
全参数微调是对预训练大模型的所有参数（包括底层词嵌入、中间特征提取层和顶层任务适配层）进行更新优化的微调方式。通过在下游任务数据上进行梯度反向传播，使模型整体适应新任务需求，相比部分参数微调或LoRA微调，能更充分利用预训练模型的泛化能力，在数据差异大或任务复杂度高的场景下表现更优。但该方法存在计算资源消耗高、小数据集易过拟合等问题，需结合学习率调整、梯度 checkpointing 等技术缓解。

本次实验中，模型通过学习delicate_medical_r1_data数据集中的“问题-思考过程-答案”映射关系，掌握医学问题的推理逻辑，最终能根据用户输入的医学问题，生成包含明确思考过程和专业答案的组合回复。

## 三、实验步骤
### （一）环境搭建
1. 确保计算机安装Python>=3.8及CUDA环境，具备≥32GB显存的英伟达/昇腾显卡。
2. 执行一键安装命令配置依赖库：
```bash
pip install swanlab modelscope==1.22.0 "transformers>=4.50.0" datasets==3.2.0 accelerate pandas addict
```
3. 验证环境依赖版本：modelscope==1.22.0、transformers==4.51.3、datasets==3.2.0等（与实验测试版本一致）。

### （二）数据集准备
1. 数据集介绍：delicate_medical_r1_data数据集用于医学对话模型训练，包含Instruction、question、think、answer、metrics五列，本次实验选取question（用户问题）、think（推理过程）、answer（最终答案）三列核心数据。
2. 数据处理流程：
   - 从Modelscope加载数据集，按9:1比例随机划分训练集（train.jsonl）和验证集（val.jsonl）。
   - 定义数据格式转换函数，将原始数据重构为“instruction+input+output”格式，其中output为“think标签+思考过程+answer内容”的组合形式。
   - 生成训练集和验证集的格式化文件（train_format.jsonl、val_format.jsonl），用于模型输入。

### （三）模型加载
1. 通过Modelscope下载Qwen3-1.7B模型至本地目录，利用transformers库加载模型权重和tokenizer：
```python
# 下载模型
model_dir = snapshot_download("Qwen/Qwen3-1.7B", cache_dir="/root/autodl-tmp/", revision="master")
# 加载tokenizer和模型
tokenizer = AutoTokenizer.from_pretrained("/root/autodl-tmp/Qwen/Qwen3-1.7B", use_fast=False, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained("/root/autodl-tmp/Qwen/Qwen3-1.7B", device_map="auto", torch_dtype=torch.bfloat16)
model.enable_input_require_grads()  # 开启梯度检查点支持
```

### （四）训练配置
1. 数据集预处理：定义process_func函数，将格式化数据转换为模型可接受的输入格式（input_ids、attention_mask、labels），设置最大序列长度为2048，超出部分截断。
2. 训练参数设置（TrainingArguments）：
参数                        取值                                   说明
output_dir                  /root/autodl-tmp/output/Qwen3-1.7B     模型保存路径
per_device_train_batch_size 1                                      单设备训练批次大小
per_device_eval_batch_size  1                                      单设备验证批次大小
gradient_accumulation_steps 4                                      梯度累积步数
eval_strategy               steps                                  按步数进行验证
eval_steps                  100                                    每 100 步验证一次
logging_steps               10                                     每 10 步记录一次日志
num_train_epochs            2                                      训练轮数
learning_rate               1e-4                                   学习率
gradient_checkpointing      True                                   启用梯度检查点
report_to                   swanlab                                训练日志上报至 SwanLab

3. 初始化Trainer：传入模型、训练参数、训练集、验证集及数据整理器，配置完成后启动训练。

### （五）训练监控
1. 注册SwanLab账号，获取API Key并在训练启动时配置。
2. 通过SwanLab实时监控训练过程中的核心指标（train loss、eval loss）、硬件资源占用（GPU利用率、内存占用）等。
3. 训练结束后，在SwanLab平台查看实验日志、生成结果及指标可视化图表。

## 四、实验结果与分析
### （一）训练指标分析
训练过程中核心关注train loss（训练损失）和eval loss（验证损失），指标变化如下：
- train loss：在epoch交替阶段呈阶梯式下降，表明模型在训练集上持续学习并拟合数据。
- eval loss：第1轮epoch中随训练推进逐渐下降，第2轮epoch反而上升，出现典型的过拟合现象。

原因分析：数据集规模（2000+条）相对较小，全参数微调在1个epoch后已充分学习训练数据特征，继续训练会导致模型过度拟合训练集噪声，降低泛化能力。因此，该任务下全参数微调的最优训练轮数为1个epoch。
![img_2.png](img_2.png)
### （二）模型生成效果评估
选取验证集中3条医学问题进行测试，模型输出结果符合预期，示例如下：

**问题**：医生，我最近胃部不适，听说有几种抗溃疡药物可以治疗，您能详细介绍一下这些药物的分类、作用机制以及它们是如何影响胃黏膜的保护与损伤平衡的吗？

**模型输出**：
<escapeShell 
嗯，用户问的是抗溃疡药物的分类、作用机制，以及它们如何影响胃黏膜的保护和损伤平衡。首先，我需要回忆一下抗溃疡药物的主要分类。记得以前学过，抗溃疡药物通常分为几大类，比如抑酸药、胃黏膜保护剂、促胃动力药和抗幽门螺杆菌药物。可能还有其他类型，比如吸附剂之类的，但可能用户的问题里没有提到，所以可能不需要展开。

接下来，每个类别的具体药物例子。比如抑酸药，常见的有H2受体拮抗剂和质子泵抑制剂。比如雷尼替丁、奥美拉唑这些。作用机制是抑制胃酸分泌，特别是H2受体拮抗剂通过阻断组胺引起的胃酸分泌，而质子泵抑制剂直接作用于胃酸分泌的最后一步，抑制质子泵。这部分需要详细说明。

胃黏膜保护剂的话，比如硫糖铝、铋剂，它们的作用是形成保护层，或者促进黏液分泌，比如硫糖铝可能通过黏附在黏膜表面形成保护膜，而铋剂可能促进黏液分泌，同时可能有中和胃酸的作用？或者可能主要是中和作用？需要确认。另外，胶体果胶铋可能也是例子。

促胃动力药比如多潘立酮、西沙必利，作用是增强胃蠕动，减少胃酸反流，这样胃排空快，可能减少溃疡形成。但用户的问题里提到的是促进胃排空，所以这部分需要说明。

抗幽门螺杆菌的药物通常包括抗生素，比如阿莫西林、克拉霉素，但抗幽门螺杆菌药物可能还有三联或四联疗法，比如加上PPI和铋剂。需要提到这些药物的作用机制是抑制幽门螺杆菌的生长，比如抗生素杀灭细菌，而PPI可能同时抑制胃酸分泌，但如果是抗幽门螺杆菌药物的话，可能是指专门针对该病的药物，比如可能还有铋剂或者其他药物？

不过用户的问题里提到抗幽门螺杆菌药物，可能需要明确是单独针对幽门螺杆菌，还是包括抗生素和PPI。可能需要指出，抗幽门螺杆菌药物通常包括抗生素和PPI，而PPI本身是抑酸药。所以可能需要说明这些药物如何通过抑制胃酸分泌和杀灭细菌来减少溃疡。

然后，关于作用机制如何影响胃黏膜的保护和损伤平衡。比如，抑酸药减少胃酸，从而减少对黏膜的侵蚀，同时保护剂形成保护层，促进黏液分泌，增强黏膜屏障。促胃动力药通过增加胃蠕动，减少胃酸反流，从而保护黏膜。而抗幽门螺杆菌药物通过减少胃酸分泌和杀灭细菌，减少损伤因素。

可能需要检查是否有遗漏的药物分类，比如吸附剂如活性炭，或者中和剂如氢氧化铝，但用户的问题可能只关注主要的四类。另外，是否需要提到铋剂的其他作用，比如促进黏液分泌和前列腺素合成？比如胶体果胶铋可能含有前列腺素，增强黏液分泌。

在解释机制时，要确保每个药物的作用点和如何影响保护和损伤。例如，抑酸药直接减少胃酸，而保护剂形成物理屏障。促胃动力药通过改变胃排空模式，减少反流，从而减少损伤。抗幽门螺杆菌药物通过减少胃酸和杀灭病原体，两者都减少损伤。

可能需要确认每个药物的正确分类和例子是否正确，比如西沙必利是否属于促胃动力药，或者是否属于H2受体拮抗剂？西沙必利其实是属于促胃动力药，因为它的作用是增强胃排空。而奥美拉唑是PPI，属于抑酸药。需要确保这些分类正确。

另外，用户提到自己胃部不适，可能需要建议就医，但答案里已经包含这点，所以没问题。

总结下来，结构应该是先分类，再每个类别下的药物例子和作用机制，然后说明这些机制如何影响保护和损伤平衡。需要确保每个部分都清晰，逻辑连贯，并且覆盖用户的问题点。
</escapeShell>
当然可以。抗溃疡药物主要分为四类：抑酸药、胃黏膜保护剂、促胃动力药和抗幽门螺杆菌药物。抑酸药如H₂受体拮抗剂和质子泵抑制剂，它们的作用是减少胃酸的分泌，从而减轻对胃黏膜的损伤。胃黏膜保护剂如硫糖铝和胶体果胶铋，它们能帮助形成一层保护膜，覆盖在胃黏膜表面，减少胃酸和胃蛋白酶对黏膜的侵蚀。促胃动力药如多潘立酮和西沙必利，通过增强胃部的蠕动，减少胃内食物的滞留时间，从而降低溃疡的风险。抗幽门螺杆菌药物则通过抑制幽门螺杆菌的生长，减少其对胃黏膜的伤害。这些药物的共同目标是通过不同的机制来平衡胃黏膜的保护因素和损伤因素，帮助溃疡愈合。如果您有具体的症状或担心某种药物，可以告诉我，我会为您推荐合适的治疗方案。

**效果总结**：
1. 模型成功生成“思考过程+最终答案”的组合回复，思考过程前后通过特定标签区分，符合实验设计要求。
2. 回答内容专业、逻辑连贯，准确覆盖药物分类、作用机制及对胃黏膜平衡的影响等核心问题点，展现出良好的医学知识掌握能力。
3. 思考过程完整，体现了逐步分析、验证知识点的推理逻辑，与DeepSeek R1的回复风格一致。

## 五、实验结论与展望
### （一）实验结论
1. 以Qwen3-1.7B为基座模型，通过全参数微调在delicate_medical_r1_data数据集上训练，成功实现了医学领域带推理过程的对话回复功能，模型输出符合预期。
2. 全参数微调能充分挖掘预训练模型的泛化能力，在医学专业问答任务中表现出优异的适配性，但在小数据集（2000+条）场景下易过拟合，建议训练轮数控制为1个epoch。
3. SwanLab工具能有效监控训练过程中的核心指标与生成效果，为实验优化提供了直观的数据支撑，适配性良好。
![img_1.png](img_1.png)
### （二）改进方向与展望
1. 数据层面：扩大数据集规模，增加更多医学细分领域（如内科、外科、儿科等）的对话数据，减少过拟合风险；引入数据增强技术（如同义词替换、句式改写）提升数据多样性。
2. 训练策略：针对小数据集场景，可采用LoRA微调替代全参数微调，降低显存占用（无需32GB显存），同时缓解过拟合问题。
3. 模型优化：调整训练超参数（如降低学习率、增加正则化项），进一步提升模型泛化能力；尝试Qwen3-7B等更大参数量模型，探索性能上限。
4. 应用拓展：将微调后的模型部署为医学咨询工具，结合实际应用场景收集反馈，持续迭代优化；扩展至多轮医学对话、病历分析等更复杂的任务。


