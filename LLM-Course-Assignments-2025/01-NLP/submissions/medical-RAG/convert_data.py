import json
import os
from datasets import load_dataset
from tqdm import tqdm

# 1. é…ç½®è·¯å¾„
LOCAL_DATASET_PATH = "./Huatuo26M-Lite" 
OUTPUT_FILE = "medical_sft_data.json"
MAX_SAMPLES = 10000

def convert_to_alpaca():
    print(f"ğŸ“‚ æ­£åœ¨è¯»å–æœ¬åœ°æ•°æ®é›†: {LOCAL_DATASET_PATH}...")
    try:
        # åŠ è½½æœ¬åœ°æ•°æ®é›†
        dataset = load_dataset(LOCAL_DATASET_PATH, split="train")
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")
        return

    sft_data = []
    print("ğŸ”„ æ­£åœ¨è½¬æ¢æ ¼å¼ä¸º Alpaca æŒ‡ä»¤é›†...")
    
    for i, item in tqdm(enumerate(dataset), total=min(len(dataset), MAX_SAMPLES)):
        if i >= MAX_SAMPLES:
            break
        if not item.get('question') or not item.get('answer'):
            continue
            
        entry = {
            "instruction": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„åŒ»ç–—æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œç»™å‡ºå‡†ç¡®ã€ä¸“ä¸šä¸”å®¢è§‚çš„åŒ»ç–—å»ºè®®ã€‚",
            "input": item['question'],
            "output": item['answer']
        }
        sft_data.append(entry)

    # ä¿å­˜æ–‡ä»¶
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(sft_data, f, ensure_ascii=False, indent=2)
        
    print(f"âœ… è½¬æ¢å®Œæˆï¼å·²ä¿å­˜ {len(sft_data)} æ¡å¾®è°ƒæ•°æ®è‡³ {OUTPUT_FILE}")

if __name__ == "__main__":
    convert_to_alpaca()