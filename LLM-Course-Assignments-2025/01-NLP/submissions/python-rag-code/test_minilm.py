# æµ‹è¯•1ï¼šåŸºæœ¬åŠŸèƒ½éªŒè¯
from sentence_transformers import SentenceTransformer
import torch

print("=== ç¬¬1æ­¥ï¼šæ£€æŸ¥ç¯å¢ƒ ===")
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
    print(f"GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

print("\n=== ç¬¬2æ­¥ï¼šä¸‹è½½å¹¶åŠ è½½æ¨¡å‹ ===")
print("æ­£åœ¨ä¸‹è½½ all-MiniLM-L6-v2ï¼ˆçº¦80MBï¼‰...")

# é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

print("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
print(f"æ¨¡å‹ç»´åº¦: {model.get_sentence_embedding_dimension()}")

print("\n=== ç¬¬3æ­¥ï¼šæµ‹è¯•ç¼–ç  ===")
# æµ‹è¯•å¥å­
sentences = [
    "How to read a file in Python?",
    "Pythonä¸­å¦‚ä½•è¯»å–æ–‡ä»¶ï¼Ÿ",
    "Using open() function to read files",
    "æ–‡ä»¶è¯»å–æ“ä½œç¤ºä¾‹"
]

print(f"ç¼–ç  {len(sentences)} ä¸ªå¥å­...")
embeddings = model.encode(sentences)

print("âœ… ç¼–ç å®Œæˆï¼")
print(f"åµŒå…¥å‘é‡å½¢çŠ¶: {embeddings.shape}")  # åº”è¯¥æ˜¯ (4, 384)
print(f"æ¯ä¸ªå‘é‡ç»´åº¦: {embeddings.shape[1]}")

print("\n=== ç¬¬4æ­¥ï¼šè®¡ç®—ç›¸ä¼¼åº¦ ===")
import numpy as np

# è®¡ç®—ç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªå¥å­çš„ç›¸ä¼¼åº¦
similarity = np.dot(embeddings[0], embeddings[1]) / (
    np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1])
)
print(f"ä¸­è‹±æ–‡é—®é¢˜ç›¸ä¼¼åº¦: {similarity:.4f}")

# ä¿å­˜æ¨¡å‹åˆ°æœ¬åœ°ï¼ˆé¿å…é‡å¤ä¸‹è½½ï¼‰
print("\n=== ç¬¬5æ­¥ï¼šä¿å­˜æ¨¡å‹åˆ°æœ¬åœ° ===")
model.save("./models/all-MiniLM-L6-v2")
print("âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: ./models/all-MiniLM-L6-v2")

print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼all-MiniLM-L6-v2 è¿è¡ŒæˆåŠŸã€‚")