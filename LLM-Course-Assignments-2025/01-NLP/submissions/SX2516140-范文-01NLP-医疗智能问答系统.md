# 🏥 MedAssist - 医疗智能问答系统

## 1 项目概述

### 1.1 项目背景

本项目基于RAG架构，构建了一个专业医疗智能问答系统。系统整合了110万+真是医疗病例数据，旨在为用户提供准确、可靠的医疗参考信息。

### 1.2 技术栈

- **编程语言**：Python3.9
- **核心框架**：LangChain，Streamlit
- **向量数据库**：ChromaDB
- **大模型**：Qwen2.5-7B

## 2 数据来源与处理

### 2.1 数据来源

数据集选用MedDialog，该数据集共包含650万条真实病例数据，由于数据集过于庞大，处理花销太大，所以采用选取每年中前5万份病例构建向量数据库。

### 2.2 数据结构

每个病例都包含以下字段：

	{
	    "id": "唯一标识符",
	    "year": "年份",
	    "disease": "疾病名称",
	    "symptoms": "症状描述",
	    "doctor_reply": "医生建议",
	    "hospital": "医院名称",
	    "department": "科室",
	    "url": "原始链接",
	    "full_text": "完整文本"
	}
### 2.3 数据处理流程

	原始文本 → 病例解析 → 文档转换 → 文本分块 → 向量化存储
	↓
	数据清洗 → 格式化标准 → 质量验证 → 批量处理
## 3 实现

- **3.1 迭代一**：完成数据预处理，向量数据库构建、Streamlit界面开发，实现基本功能。

  [RunResults](https://github.com/AuroraFan1/medical_rag/blob/main/PNG/RunResults.png)

- **3.2 迭代二**：编写代码对Qwen-2.5-7B-Instruct模型进行微调，从已经处理的数据中选取数据作为训练数据和验证数据，选取训练集大小为2959，选取验证集为329.微调在AutoDL中租用RTX 5090(32GB)进行，耗时2h，纵观整个训练流程，损失曲线持续下降，准确率曲线持续上升，训练-验证差距逐渐减小，不存在过拟合问题。

  [LoadModel](https://github.com/AuroraFan1/medical_rag/blob/main/PNG/LoadModel.png)

  [TrainVerification](https://github.com/AuroraFan1/medical_rag/blob/main/PNG/TrainVerification.png)

  [EndTraining](https://github.com/AuroraFan1/medical_rag/blob/main/PNG/EndTraining.png)

- **3.3 迭代三**：编写代码对模型进行评估，由于硬件限制，初始选择数据集数量有限，且可能质量一般，各种病例分布不均；同时由于在微调阶段随机选取训练集和验证集且数量更少，导致评估效果较差，如果能够有足够硬件支持，将数据量改进后，系统应该能提供更加真实、可靠、有价值的医疗信息服务。由于评估结果表现不佳。

  [StartEvaluation](https://github.com/AuroraFan1/medical_rag/blob/main/PNG/StartEvaluation.png)
  
  [EvaluationTime](https://github.com/AuroraFan1/medical_rag/blob/main/PNG/EvaluationTime.png)
  
  ​	我将详细介绍评估方法。首先是检索质量评估，计算问题与检索结果的相关性，通过分词，计算关键词重叠的比例，最终返回平均相关性。相关性不佳的原因也可能是由于简单的分词导致同样类型的问题不具有重叠词；第二是生成质量评估，使用三个指标分别是BLEU分数：基于n-gram重叠，比较候选文本和参考文本的n-gram重叠度；ROUGE-L分数：基于最长公共子序列的F1分数；语义相似度：基于词重叠的Jaccard相似度，相似度=交集大小 / 并集大小。最后是评估响应时间，记录查询开始到结束的时间差。
  
  ​	在做评估时，每项评估选用样本也较少，都是20-50个样本，统计意义不强。很大程度上忽略了医学实体，正确性本身较差。
  
- **3.4 迭代四**：由于可能是硬件限制导致的评估结果表现较差，选用RTX 5090，增大数据量（每年10万份病例），共选取110万病例，重新处理数据，构建向量数据库，同时选取更小的模型（Qwen-2.5-1.5B）进行微调，选取训练集大小45000，验证集大小5000，配置LoRA为r=8，alpha=16进行训练，但是在训练中的评估总是因为内存不足报错。在最后的评估中，ROUGE-L分数较低，可能原因应该是训练中没有评估引起的，幻觉率0.26，引用F1较高，达到0.9，医疗准确性按照关键词比对，准确率也高达0.8。

  

## 4 项目地址及启动

- GitHub仓库：https://github.com/AuroraFan1/medical_rag.git
- 启动方式：参照GitHub仓库README

## 5问题分析

- **数据规模与质量限制**：原始数据集包含650万病例，但因计算资源限制，仅选取每年10万份构建向量库，可能覆盖不全、分布不均。微调和评估阶段数据量小，统计意义不强，影响模型泛化能力。
- **模型评估方法简单：**使用BLEU、ROUGE-L、Jaccard等通用文本相似度指标，未引入医学知识评估（如诊断一致性、术语准确性）。 幻觉率虽低（0.26），但在医疗场景中仍存在风险。
- **训练与评估不一致：** 微调阶段未进行实时评估，导致训练效果无法及时反馈，最终评估结果不理想。

## 6未来改进方向

- **数据优化：** 引入更多高质量医学数据集（如医学教科书、指南、权威文献）； 使用医学实体识别（NER）和术语标准化，提升检索质量。
- **模型增强：** 尝试更多医学预训练模型（如BioBERT、PubMedBERT）
- **评估体系完善：** 设计医学QA专用评估指标（如诊断准确率、术语一致性、安全合规性）。

