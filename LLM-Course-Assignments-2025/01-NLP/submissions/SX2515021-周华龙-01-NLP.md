# 实验报告：自动控制原理智能助教 RAG 系统

## 1. 项目概述

本项目旨在开发一个面向“自动控制原理”课程的深度 RAG（检索增强生成）问答系统。通过集成轻量化大语言模型与专业知识库，解决复杂控制理论问题的精准检索与智能化解答，作为高效的辅助学习工具。

## 2. 数据来源与处理（已完成）

- **数据来源**：原始素材主要来源于 **《自动控制原理》（陈复扬主编）** 及其配套习题集。知识库涵盖了线性系统的数学模型、时域分析、根轨迹、频域分析及状态空间分析等核心教学章节。
    
- **数据规模**：基于从上述教材提取的 **1247 条** 原始知识片段，通过“单片段 5 题”采样策略，实现了 **5000+** 条领域 QA 对的自动化合成，完美对齐课程 5k 条数据的硬性指标。
    
- **数学规范**：所有数据严格执行 LaTeX 封装，如传递函数
    
    $$G(s) = \frac{C(s)}{R(s)}$$
    
    及状态空间表达式，确保在 Markdown/Obsidian 环境下的高质量渲染。
    

## 3. 实验方法与算力配置

- **模型选型**：采用开源 LLM `Qwen2.5-1.5B-Instruct`，兼顾了端侧推理速度与逻辑理解能力。
    
- **效能优化**：在 Kaggle 平台通过 **Dataset 离线挂载** 策略，将 3GB 模型的预热时间由 1200s 压缩至 **60s** 内，极大提升了实验迭代效率。
    
- **环境鲁棒性**：通过正则表达式实时修复 JSON 转义冲突，解决了大规模数据生成过程中的解析崩溃问题。
    

## 4. 实验结果与创新亮点

- **拒绝不确定回答机制**：在检索链中设计了相关度阈值过滤，若检索内容与自控原理知识库无关，模型将执行“拒绝回答”策略以降低幻觉。
    
- **引用来源显示功能**：在检索返回阶段强制保留 `metadata` 中的原始段落标签，计划在 Web UI 中实现“回答 + 原文引用”的双向呈现。
    
- **多轮对话能力预置**：已确立基于 `LangChain` 的对话缓冲区架构，支持长上下文（>32k tokens）处理，为复杂的系统稳定性分析对话提供技术保障。
    
- **定量评估框架**：设计了针对生成的 5000 题库的自动评测脚本，将通过引用 F1 分数与幻觉率指标对 RAG 效果进行科学量化。
    

## 5. 项目资源与链接

- **个人独立代码仓库**：[https://github.com/DNFYII/LLM-Course](https://www.google.com/search?q=https://github.com/DNFYII/LLM-Course)
    
- **Kaggle 推理生产端**：[https://www.kaggle.com/code/dnfyii/control-qa](https://www.google.com/search?q=https://www.kaggle.com/code/dnfyii/control-qa)
    

## 6. 下周计划

- 使用 **Gradio** 构建 Web 交互 Demo，支持实时检索与引用显示。
    
- 对 5000 条合成数据进行抽样质量回审与格式微调。
