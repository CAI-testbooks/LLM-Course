# 基于LLM的具身智能体系统设计与实现

## 1. 任务背景与目标
本项目对应课程方向03：智能体及具身智能综合作业。
目标是构建一个基于大语言模型（LLM）的具身智能体，
使其能够在模拟环境中完成多步决策与交互任务。

## 2. 系统整体架构
系统整体采用模块化设计，主要包括：
- 感知模块：负责从环境中获取观测信息
- 决策模块：基于大语言模型进行任务理解与高层规划
- 行为执行模块：将规划结果转化为具体动作
- 环境交互接口：与模拟环境进行通信

## 3. 关键技术实现
- 使用大语言模型作为智能体核心决策单元
- 通过 Prompt 设计实现任务分解与行为规划
- 引入历史信息作为上下文，提高决策一致性

## 4. 实验设置
- 模拟环境：Habitat / AI2-THOR
- 使用模型：Deepseek
- 运行平台：Ubuntu 22.04
- 计算资源：RTX 4090

## 5. 实验结果与分析
实验结果表明，该具身智能体能够完成指定任务流程，
在多步交互场景中具备一定的鲁棒性。
同时，对失败案例进行了分析，主要原因包括感知误差和规划不完整。

## 6. 创新点与改进
- 将 LLM 引入具身智能体的高层规划中
- 采用模块化架构，便于扩展和复现
- 对智能体决策流程进行了工程层面的优化

## 7. 代码与复现说明
代码仓库地址：
https://github.com/Atroheim/Agent-Embodied

代码仓库中提供了完整的环境配置与运行说明，
可根据 README.md 进行复现实验。

## 8. 改进方向
1. 微调行动策略、加入记忆模块，提升任务成功率。
2. 在模拟器中运行Demo，录制视频。
3. 评估任务成功率、步骤效率、泛化能力。

