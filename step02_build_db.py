import os
import fitz  # PyMuPDF
from rapidocr_onnxruntime import RapidOCR
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document

# ================= é…ç½®åŒºåŸŸ =================
PDF_PATH = "data/textbook.pdf"
DB_PATH = "vector_db"


PAGE_OFFSET = 10


# ===========================================

def load_pdf_with_offset(file_path):
    print(f"ğŸš€ [1/3] æ­£åœ¨åŠ è½½: {file_path}")
    print(f"    â„¹ï¸ å·²å¯ç”¨é¡µç ä¿®æ­£: PDFé¡µç  - {PAGE_OFFSET} = ä¹¦æœ¬é¡µç ")

    docs = []
    ocr = RapidOCR()

    with fitz.open(file_path) as pdf:
        total = len(pdf)
        print(f"    - æ£€æµ‹åˆ° PDF å…± {total} é¡µ")

        for i, page in enumerate(pdf):
            # ------------------------------------------------
            # æ ¸å¿ƒä¿®æ­£é€»è¾‘
            # ------------------------------------------------
            physical_page = i + 1  # PDFæ–‡ä»¶çš„ç¬¬å‡ å¼ çº¸
            logical_page = physical_page - PAGE_OFFSET  # ä¿®æ­£åçš„ä¹¦æœ¬é¡µç 

            # å¦‚æœæ˜¯å‰ 10 é¡µï¼ˆç›®å½•ã€å‰è¨€ç­‰ï¼‰ï¼Œæ˜¾ç¤ºä¸º "å‰è¨€-xx"
            if logical_page <= 0:
                page_label = f"å‰è¨€/ç›®å½•"
            else:
                page_label = f"{logical_page}"
            # ------------------------------------------------

            # 1. å°è¯•ç›´æ¥æå–æ–‡å­—
            text = page.get_text()

            # 2. OCR è¡¥æ•‘ï¼ˆé˜²æ­¢æ‰«æç‰ˆè¯»ä¸å‡ºå­—ï¼‰
            if len(text.strip()) < 5:
                try:
                    pix = page.get_pixmap()
                    img_data = pix.tobytes("png")
                    result, _ = ocr(img_data)
                    if result:
                        text = "\n".join([line[1] for line in result])
                except:
                    pass

            # 3. å­˜å…¥ Document
            if text.strip():
                docs.append(Document(
                    page_content=text,
                    metadata={
                        "source": os.path.basename(file_path),
                        # è¿™é‡Œå­˜å…¥ä¿®æ­£åçš„é¡µç 
                        "page": page_label
                    }
                ))

                # æ‰“å°æ—¥å¿—è®©æˆ‘ä»¬å®‰å¿ƒ
                if physical_page == 11:
                    print(f"      > âœ… éªŒè¯ç‚¹ï¼šPDFç¬¬11é¡µ å·²æ ‡è®°ä¸º -> ç¬¬ {page_label} é¡µ")
                elif physical_page % 50 == 0:
                    print(f"      > å¤„ç†ä¸­ï¼šPDFç¬¬{physical_page}é¡µ -> ç¬¬ {page_label} é¡µ")

    return docs


def main():
    # 1. åŠ è½½
    docs = load_pdf_with_offset(PDF_PATH)
    print(f"âœ… æå–å®Œæˆï¼Œå…± {len(docs)} é¡µæœ‰æ•ˆå†…å®¹ã€‚")

    # 2. åˆ‡åˆ†
    print("âœ‚ï¸ [2/3] æ­£åœ¨åˆ‡åˆ†æ–‡æœ¬...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    splits = text_splitter.split_documents(docs)

    # 3. å­˜å…¥
    print("ğŸ’¾ [3/3] æ­£åœ¨é‡å»ºå‘é‡æ•°æ®åº“...")
    embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")
    db = FAISS.from_documents(splits, embeddings)
    db.save_local(DB_PATH)
    print("ğŸ‰ æ•°æ®åº“é‡å»ºå®Œæ¯•ï¼ç°åœ¨é¡µç åº”è¯¥å®Œå…¨å¯¹ä¸Šäº†ã€‚")


if __name__ == "__main__":
    main()